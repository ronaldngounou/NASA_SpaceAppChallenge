{"cells": [{"cell_type": "code", "execution_count": 2, "id": "cfb250ed-7e4c-41e7-a2b7-ea2a3d18949b", "metadata": {}, "outputs": [{"data": {"text/html": "<style>pre { white-space: pre !important; }</style>", "text/plain": "<IPython.core.display.HTML object>"}, "metadata": {}, "output_type": "display_data"}], "source": "from IPython.core.display import HTML\ndisplay(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"}, {"cell_type": "code", "execution_count": 21, "id": "e2e9567a-b162-4e0a-9eb4-1b4a71195db0", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom google.cloud import storage\nfrom pyspark.sql.functions import col, create_map, lit, concat\nfrom itertools import chain\nimport json"}, {"cell_type": "code", "execution_count": 22, "id": "aed5e814-c6c1-49d5-b08f-31e100d32f19", "metadata": {}, "outputs": [], "source": "# create spark session\nspark = SparkSession.builder.getOrCreate()"}, {"cell_type": "code", "execution_count": 23, "id": "8ffd08ec-704e-4fdd-bdfb-7afc588f3b1d", "metadata": {}, "outputs": [], "source": "# create file links\nbucket = \"dataproc-staging-us-central1-123791584787-rwa2xlbh\"\ndata_folder = \"data\"\nclient = storage.Client()\nfiles = [blob.name for blob in client.list_blobs(bucket, prefix=data_folder)]\n#files = [blob.path for blob in client.list_blobs(bucket, prefix=data_folder)]\nfiles = [\"gs://\"+bucket+\"/\"+file for file in files]\n#files"}, {"cell_type": "code", "execution_count": 24, "id": "adcb1f69-9561-4b0d-94b3-8050fd99b131", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "21/11/18 08:33:31 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n21/11/18 08:33:32 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n21/11/18 08:33:33 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n21/11/18 08:33:33 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n21/11/18 08:33:34 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n21/11/18 08:33:34 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n21/11/18 08:33:34 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n21/11/18 08:33:35 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n21/11/18 08:33:36 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n21/11/18 08:33:36 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n21/11/18 08:33:36 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n21/11/18 08:33:37 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n21/11/18 08:33:37 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}], "source": "# read files\ndf_list=[]\nfor filename in sorted(files):\n    data = spark.read.option(\"header\",True).option(\"multiLine\", \"true\").csv(filename)\n    data = data.drop(\"description\").drop(\"tags\").drop(\"channel_id\")\n    if \"BR\" in filename:\n        data = data.withColumn(\"region\", lit(\"Brazil\"))\n    elif 'CA' in filename:\n        data = data.withColumn(\"region\", lit(\"Canada\"))\n    elif 'DE' in filename:\n        data = data.withColumn(\"region\", lit(\"Germany\"))\n    elif 'FR' in filename:\n        data = data.withColumn(\"region\", lit(\"France\"))\n    elif 'GB' in filename:\n        data = data.withColumn(\"region\", lit(\"Great Britain\"))\n    elif 'IN' in filename:\n        data = data.withColumn(\"region\", lit(\"India\"))\n    elif 'JP' in filename:\n        data = data.withColumn(\"region\", lit(\"Japan\"))\n    elif 'KR' in filename:\n        data = data.withColumn(\"region\", lit(\"Korea\"))\n    elif 'MX' in filename:\n        data = data.withColumn(\"region\", lit(\"Mexico\"))\n    elif 'RU' in filename:\n        data = data.withColumn(\"region\", lit(\"Russia\"))\n    elif 'US' in filename:\n        data = data.withColumn(\"region\", lit(\"USA\")) \n    df_list.append(data)"}, {"cell_type": "code", "execution_count": 25, "id": "14d8c6ed-ce3a-4b75-8268-b60c3b21e470", "metadata": {"tags": []}, "outputs": [], "source": "df_list[0].show(10)"}, {"cell_type": "code", "execution_count": 26, "id": "955f4b7b-94dc-425b-a12e-e188605e3119", "metadata": {"jupyter": {"source_hidden": true}, "tags": []}, "outputs": [], "source": "df_all = df_list[0]\nfor i in range(1,len(df_list),1):\n    df_all = df_all.union(df_list[i])\n"}, {"cell_type": "code", "execution_count": 27, "id": "d21e336a-ac54-4c39-9848-4628af927b8b", "metadata": {}, "outputs": [], "source": "df_all = df_all.drop(\"channelId\").drop(\"channelTitle\").drop(\"tags\").drop(\"comments_disabled\").drop(\"ratings_disabled\").drop(\"description\")"}, {"cell_type": "code", "execution_count": 10, "id": "05891bd3-5354-411f-bc42-660e8699f66c", "metadata": {}, "outputs": [], "source": "# # Run some checks\n# print(df_all.count())\n# print([df.count() for df in df_list])\n# print(len(df_all.columns))\n# print([len(df.columns) for df in df_list])"}, {"cell_type": "code", "execution_count": 28, "id": "2aeeab7b-3ff4-4dd0-88e8-a5cd918a8a3d", "metadata": {}, "outputs": [], "source": "df_all = df_all.withColumn(\"video_url_prefix\", lit(\"https://www.youtube.com/watch?v=\"))\\\n                .withColumn(\"video_links\", concat(col(\"video_url_prefix\"), col(\"video_id\")))"}, {"cell_type": "code", "execution_count": 29, "id": "36105136-569b-45b2-b724-948369f8520e", "metadata": {}, "outputs": [], "source": "df_all = df_all.drop(\"video_url_prefix\")"}, {"cell_type": "code", "execution_count": 30, "id": "dab6c68f-1395-4961-86b4-9cd2e42caac0", "metadata": {}, "outputs": [], "source": "# get the categories\ncategories_folder = \"categories\"\ncategories_list = [json.loads(blob.download_as_string(client=None)) for blob in client.list_blobs(bucket, prefix=categories_folder)]\ncategories_map = {}\nfor caregories in categories_list: \n    for item in caregories[\"items\"]:\n        categories_map[item[\"id\"]] = item[\"snippet\"][\"title\"]"}, {"cell_type": "code", "execution_count": 31, "id": "95724de0-af6a-42dc-864f-2222426a8ec7", "metadata": {}, "outputs": [], "source": "#source: https://stackoverflow.com/questions/42980704/pyspark-create-new-column-with-mapping-from-a-dict\nmapping_expr = create_map([lit(x) for x in chain(*categories_map.items())])\ndf_all =df_all.withColumn(\"category_name\", mapping_expr.getItem(col(\"categoryId\")))"}, {"cell_type": "code", "execution_count": 32, "id": "c0478196-8435-4574-bf40-fa7b750fd31f", "metadata": {"tags": []}, "outputs": [], "source": "df_all.show(3)"}, {"cell_type": "code", "execution_count": 34, "id": "cc5a1175-c294-4b57-8492-5e79f83dc3d4", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df_all.write.csv(\"gs://\"+bucket+\"/clean_data/\")"}, {"cell_type": "code", "execution_count": 38, "id": "cbf6d778-632d-4956-8601-1253067382dd", "metadata": {}, "outputs": [], "source": "data = \"gs://\"+bucket+\"/clean_data/\""}, {"cell_type": "code", "execution_count": 41, "id": "5beefad9-9d71-4bea-9e3d-5ee3ec9f4375", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "21/11/18 08:46:59 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n21/11/18 08:46:59 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}], "source": "dataframe = spark.read.option(\"header\",True).option(\"multiLine\", \"true\").csv(data)"}, {"cell_type": "code", "execution_count": 42, "id": "6ee78c22-af33-4254-b1c4-232a06e3f74e", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+----------------------------------------------+--------------------+---+--------------------+-------+------+-----+-----+----------------------------------------------+------+-------------------------------------------+----------------+\n|s9FH4rDMvds|LEVEI UM FORA? FINGI ESTAR APAIXONADO POR ELA!|2020-08-11T22:21:49Z| 22|2020-08-12T00:00:00Z| 263835| 85095|  487| 4500|https://i.ytimg.com/vi/s9FH4rDMvds/default.jpg|Brazil|https://www.youtube.com/watch?v=s9FH4rDMvds|  People & Blogs|\n+-----------+----------------------------------------------+--------------------+---+--------------------+-------+------+-----+-----+----------------------------------------------+------+-------------------------------------------+----------------+\n|jbGRowa5tIk|                          ITZY \u201cNot Shy\u201d M/...|2020-08-11T15:00:13Z| 10|2020-08-12T00:00:00Z|6000070|714310|15176|31040|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|           Music|\n|3EfkCrXKZNs|                          Oh Juliana PAR\u00d3DI...|2020-08-10T14:59:00Z| 22|2020-08-12T00:00:00Z|2296748| 39761| 5484|    0|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|  People & Blogs|\n|gBjox7vn3-g|                          Contos de Runeter...|2020-08-11T15:00:09Z| 20|2020-08-12T00:00:00Z| 300510| 46222|  242| 2748|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|          Gaming|\n|npoUGx7UW7o|                          Entrevista com Th...|2020-08-11T20:04:02Z| 23|2020-08-12T00:00:00Z| 327235| 22059| 3972| 2751|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|          Comedy|\n|Vu6PNpYKu2U|                          DICAS DA RODADA 2...|2020-08-11T17:14:20Z| 17|2020-08-12T00:00:00Z| 117217| 14220|  106|  785|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|          Sports|\n|ly8jXKq_9AE|                          LIVE PLAYLIST DA ...|2020-08-12T03:31:08Z| 10|2020-08-12T00:00:00Z|  93022|  7595|  166|  136|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|           Music|\n|QAUqqcEU0Xc|                          PEDI ELA EM NAMOR...|2020-08-11T00:02:35Z| 24|2020-08-12T00:00:00Z|1427499|225365| 2287| 9647|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|   Entertainment|\n|eA4FRvf6vdM|                          AO VIVO - Apresen...|2020-08-12T00:58:57Z| 17|2020-08-12T00:00:00Z|  97711| 17153|   65|  226|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|          Sports|\n|8f70QZQB4UA|                          MASTERCHEF BRASIL...|2020-08-12T08:02:01Z| 24|2020-08-12T00:00:00Z| 199577|  7700|  129|  874|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|   Entertainment|\n|oH8wiqTGKrM|                          DIA DE FAZER COMP...|2020-08-11T23:36:58Z| 24|2020-08-12T00:00:00Z|  41592| 18109|   88|  690|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|   Entertainment|\n|OxwD-3E6M-k|                          Kemilly Santos, A...|2020-08-11T15:00:14Z| 10|2020-08-12T00:00:00Z| 117085| 15113|  153|  914|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|           Music|\n|uD5dJXCa_1s|                          Isadora Pompeo e ...|2020-08-11T13:00:09Z| 10|2020-08-12T00:00:00Z| 175034| 26722|  251| 1068|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|           Music|\n|8irga_AqRdw|                          Minicurso Gratuit...|2020-08-12T02:16:40Z| 27|2020-08-12T00:00:00Z|  33204|  8445|   58|  206|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|       Education|\n|XZpj2Lx4HnA|                          REENCONTREI MINHA...|2020-08-11T22:54:09Z| 24|2020-08-12T00:00:00Z|1007452|189397| 3742|21822|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|   Entertainment|\n|NQzNn_wQ_Vk|                          ESTOU LOIRA, DESI...|2020-08-11T19:08:16Z| 22|2020-08-12T00:00:00Z|  81679| 19212|  360| 1672|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|  People & Blogs|\n|BTYfaXKDDHY|                          FREE FIRE AO VIVO...|2020-08-11T02:27:10Z| 20|2020-08-12T00:00:00Z|1123945|129849| 1292|  746|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|          Gaming|\n|7WLxd6b2ayI|                               N\u00d3S VOLTAMOS???|2020-08-11T15:54:23Z| 24|2020-08-12T00:00:00Z| 422511|117479| 1471| 8318|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|   Entertainment|\n|NXt6tzwH1V8|                          A MELHOR NUBANK D...|2020-08-11T23:37:51Z| 22|2020-08-12T00:00:00Z|  58286| 10104|   79|  465|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|  People & Blogs|\n|4wvIs_ckfHg|                          CACHORRO QUENTE P...|2020-08-11T22:00:01Z| 22|2020-08-12T00:00:00Z|  48761|  6557|   82|  604|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|  People & Blogs|\n|EnHKFPruYsQ|                          350z do Renato Ga...|2020-08-11T13:17:45Z|  2|2020-08-12T00:00:00Z| 186019| 14737|  201|  338|                          https://i.ytimg.c...|Brazil|                       https://www.youtu...|Autos & Vehicles|\n+-----------+----------------------------------------------+--------------------+---+--------------------+-------+------+-----+-----+----------------------------------------------+------+-------------------------------------------+----------------+\nonly showing top 20 rows\n\n"}], "source": "dataframe.show()"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 5}